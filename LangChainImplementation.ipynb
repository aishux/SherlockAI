{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import nest_asyncio\n",
    "import ssl\n",
    "import certifi\n",
    "import re\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from CosmosGremlinGraph.GremlinGraph import GremlinGraph\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.tools import Tool\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_graphml('CosmosGremlinGraph/graph.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "ssl_context = ssl.create_default_context(cafile=certifi.where())\n",
    "\n",
    "# Replace these values with your Cosmos DB Gremlin endpoint and primary key\n",
    "COSMOS_DB_ENDPOINT = 'wss://sherlock-ai-account.gremlin.cosmos.azure.com:443/'\n",
    "COSMOS_DB_PRIMARY_KEY = '=='\n",
    "DATABASE = 'sherlock-db'\n",
    "GRAPH = 'sherlock-ai-graph'\n",
    "\n",
    "graph = GremlinGraph(\n",
    "    url=COSMOS_DB_ENDPOINT,\n",
    "    username=f\"/dbs/{DATABASE}/colls/{GRAPH}\",\n",
    "    password=COSMOS_DB_PRIMARY_KEY,\n",
    "    ssl_context=ssl_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI Configuration\n",
    "AZURE_OPENAI_ENDPOINT = \"https://aishu-m8m23xc2-eastus2.cognitiveservices.azure.com/\"\n",
    "AZURE_OPENAI_KEY = \"2TpUnxlwFmgMU5xCyFc4HncL43stei4En4SRL6KbD6oH5062zE7hJQQJ99BCACHYHv6XJ3w3AAAAACOGWq6g\"\n",
    "AZURE_DEPLOYMENT_NAME = \"gpt-4o\"\n",
    "\n",
    "# Initialize the Azure Chat Model in LangChain\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    openai_api_version=\"2025-01-01-preview\",\n",
    "    azure_deployment=AZURE_DEPLOYMENT_NAME,\n",
    "    api_key=AZURE_OPENAI_KEY,\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_prompt = \"\"\"\n",
    "You are a Criminal Tracking & Analysis Agent using Cosmos Gremlin and NetworkX.\n",
    "Primary Goal: use Gremlin queries or NetworkX code to answer user questions about the crime network.\n",
    "In case of hybrid queries follow this sequence:\n",
    "- Get the filtered data using AQL\n",
    "- Use this data in the networkx code.\n",
    "Respond to user queries with the minimal steps required.\n",
    "Give detailed response and use proper formatting(using bullet points). Make sure to include the results in your output.\n",
    "\"\"\"\n",
    "\n",
    "gremlin_msg = \"\"\"\n",
    "This is a Chicago Crime Network stored in Azure Cosmos DB Gremlin Graph, with the following node and edge labels:\n",
    "crime node is connected to all the other nodes by the edges mentioned.\n",
    "All other nodes are having a inbound connection from crime\n",
    "Vertex labels are the following: crime,location,crime_type,criminal,district,date,hour Edge labes are the following: located_at,is_type,occurred_at_hour,occurred_on_date,involved_criminal,located_in_district Vertices have following properties: [\"crime\":[\"crime_id\"],\"location\":[\"location\"],\"crime_type\":[\"crime_type\"],\"criminal\":[\"name\"],\"district\":[\"district\"],\"date\":[\"date\"],\"hour\":[\"hour\"]]'\n",
    "MAKE SURE TO ALWAYS OUTPUT ID OF THE NODE. FILTER THE OUTPUT TO MINIMUM REQUIRED DATA WITH ONLY KEYWORDS NOT A MAP.\n",
    "ONLY GIVE ME THE GREMLIN QUERY. DO NOT PROVIDE ANY INSTRUCTIONS.\n",
    "\"\"\"\n",
    "\n",
    "gremlin_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            gremlin_msg\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "gremlin_chain = gremlin_prompt | llm\n",
    "\n",
    "\n",
    "networkx_msg = \"\"\"\n",
    "** THERE SHOULD BE NO TEXT IN THE OUTPUT, JUST CODE **\n",
    "1. ONLY provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
    "2. Code must reference `G` as the networkx graph.\n",
    "3. Use only `networkx (nx)`. nx is already available so no need to import.\n",
    "4. Store the final result in `FINAL_RESULT`.\n",
    "5. Use the correct algorithm\n",
    "\n",
    "Python Code:\n",
    "\"\"\"\n",
    "\n",
    "networkx_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            networkx_msg\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "networkx_chain = networkx_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_gremlin(query: str) -> str:\n",
    "    \"\"\"Strictly receives natural language queries then Converts to Gremlin queries and executes it in Azure Cosmos Gremlin.\"\"\"\n",
    "    print(\"Query is: \", query)\n",
    "    print(\"Executing Gremlin Query...\")\n",
    "\n",
    "    gremlin_query = gremlin_chain.invoke({\"input\": query}).content.split(\"\\n\")[1]\n",
    "\n",
    "    print(\"Gremlin query: \" , gremlin_query)\n",
    "\n",
    "    return graph.query(gremlin_query)\n",
    "\n",
    "\n",
    "def text_to_nxgraph(query: str) -> str:\n",
    "    \"\"\"Uses networkx to analyze the crime graph.\"\"\"\n",
    "\n",
    "    print(\"Executing NetworkX Query...\")\n",
    "\n",
    "    global_vars = {\"G\": G, \"nx\": nx}\n",
    "    local_vars = {}\n",
    "\n",
    "    graph_analysis_code = networkx_chain({\"input\" : query}).content\n",
    "\n",
    "    # Strip triple backticks if present\n",
    "    cleaned_code = re.sub(r\"^```python\\n|```$\", \"\", graph_analysis_code, flags=re.MULTILINE).strip()\n",
    "\n",
    "    print(f\"Python Code: \\n\\n {cleaned_code}\")\n",
    "\n",
    "    global_vars = {\"G\": G, \"nx\": nx}\n",
    "    local_vars = {}\n",
    "\n",
    "    try:\n",
    "        exec(cleaned_code, global_vars, local_vars)\n",
    "        return local_vars.get(\"FINAL_RESULT\", \"No result found.\")\n",
    "    except Exception as e:\n",
    "        return f\"Error executing cuGraph code: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(name=\"GremlinQuery\", func=text_to_gremlin, description=\"STRICTLY only receives natural language queries then Generates and Executes Gremlin queries in Consmos DB.\"),\n",
    "    Tool(name=\"NetworkxQuery\", func=text_to_nxgraph, description=\"Generates python code and Performs networkx graph analysis.\")\n",
    "]\n",
    "\n",
    "\n",
    "agent = create_react_agent(model=llm, tools=tools)\n",
    "\n",
    "\n",
    "def query_graph(query: str) -> str:\n",
    "    \"\"\"Runs a query through the agent.\"\"\"\n",
    "    return agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query is:  g.V().has('person', 'name', 'Kristine Long').out('committed').values('location')\n",
      "Executing Gremlin Query...\n"
     ]
    }
   ],
   "source": [
    "query_graph(\"What are the locations where crime is committed by Kristine Long?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
